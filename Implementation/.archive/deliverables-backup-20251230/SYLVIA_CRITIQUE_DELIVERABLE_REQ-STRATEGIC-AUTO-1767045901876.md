# ARCHITECTURAL CRITIQUE: Performance Analytics & Optimization Dashboard
**REQ-STRATEGIC-AUTO-1767045901876**

**Prepared by:** Sylvia Chen - Senior Architect
**Date:** 2025-12-29
**Priority:** P1 - Strategic Feature
**Status:** CRITICAL ARCHITECTURAL CONCERNS IDENTIFIED

---

## EXECUTIVE SUMMARY

The Performance Analytics & Optimization Dashboard represents a critical strategic capability for system-wide performance visibility. However, the current architecture exhibits **significant gaps and scalability concerns** that must be addressed before implementation.

**VERDICT:** ‚ö†Ô∏è **CONDITIONAL APPROVAL WITH MANDATORY REVISIONS**

### Critical Issues Identified
1. ‚ùå **No Performance Metrics Collection Infrastructure** - Stub data only
2. ‚ùå **Missing Query Performance Tracking** - No database query monitoring
3. ‚ùå **Insufficient Caching Strategy** - No Redis/distributed caching
4. ‚ö†Ô∏è **Limited Real-Time Capabilities** - NATS integration incomplete
5. ‚ö†Ô∏è **No Time-Series Database** - Performance metrics stored in PostgreSQL OLAP tables

### Strengths
1. ‚úÖ **Solid OLAP Foundation** - Incremental refresh architecture proven
2. ‚úÖ **GraphQL Schema Extensibility** - Easy to add performance schema
3. ‚úÖ **Health Monitoring Base** - K8s probes and health controller functional
4. ‚úÖ **Vendor Performance Model** - Excellent template for metrics aggregation

---

## ARCHITECTURAL ASSESSMENT

### 1. CURRENT STATE ANALYSIS

#### 1.1 Monitoring Infrastructure ‚úÖ ADEQUATE (WITH GAPS)

**Existing Components:**
```
backend/src/modules/monitoring/
‚îú‚îÄ‚îÄ monitoring.module.ts          ‚úÖ Basic structure
‚îú‚îÄ‚îÄ monitoring.resolver.ts        ‚ö†Ô∏è STUB DATA ONLY
‚îî‚îÄ‚îÄ services/
    ‚îî‚îÄ‚îÄ agent-activity.service.ts ‚úÖ NATS integration working
```

**Health Monitoring:**
- **Location:** `backend/src/health/health.controller.ts`
- **Capabilities:**
  - ‚úÖ Kubernetes probes (liveness, readiness, startup)
  - ‚úÖ Database connection health
  - ‚úÖ Database latency tracking
  - ‚úÖ Connection pool utilization
  - ‚ùå **Missing:** Query performance metrics
  - ‚ùå **Missing:** API response time tracking
  - ‚ùå **Missing:** Memory/CPU metrics collection

**Current Stub Implementation (Lines 18-54 in monitoring.resolver.ts):**
```typescript
@Query()
systemHealth() {
  return {
    overall: 'OPERATIONAL',
    backend: { status: 'OPERATIONAL', responseTime: 50 },
    // ... HARDCODED VALUES - NOT REAL METRICS
  };
}
```

**ISSUE:** This is placeholder data. No actual metrics are being collected or aggregated.

#### 1.2 Performance Tracking Infrastructure ‚ùå MISSING

**What Exists:**
- Database pool metrics (basic): `totalCount`, `idleCount`
- Health check latency: Single `SELECT 1` query timing
- Agent activity tracking: Via NATS subscriptions

**What's Missing:**
1. **Query Performance Monitoring**
   - No query execution time tracking
   - No slow query detection
   - No query plan analysis
   - No N+1 query detection

2. **API Performance Metrics**
   - No GraphQL resolver timing
   - No REST endpoint metrics
   - No request/response size tracking
   - No rate limiting metrics

3. **Resource Utilization**
   - No CPU usage tracking
   - No memory heap snapshots
   - No event loop lag monitoring
   - No garbage collection metrics

4. **Business Metrics**
   - No throughput tracking (requests/sec)
   - No error rate aggregation
   - No user session metrics
   - No cache hit/miss ratios

#### 1.3 OLAP Foundation ‚úÖ EXCELLENT

**Strength:** The OLAP incremental refresh pattern from V0.0.34 migration is **world-class**:

```sql
-- From V0.0.34__convert_to_regular_table_with_incremental_refresh.sql
CREATE OR REPLACE FUNCTION refresh_bin_utilization_incremental()
RETURNS TABLE (
  locations_refreshed INTEGER,
  duration_ms INTEGER,
  status TEXT
)
```

**Performance:** 100-300x faster than materialized view refresh

**Reusability:** This pattern should be applied to performance metrics aggregation:
- `performance_metrics_cache` (hourly aggregates)
- `query_performance_cache` (slow query history)
- `api_endpoint_metrics_cache` (endpoint statistics)

### 2. PROPOSED ARCHITECTURE

#### 2.1 Performance Metrics Collection Layer

**New Service:** `backend/src/modules/monitoring/services/performance-metrics.service.ts`

```typescript
interface QueryPerformanceMetric {
  queryHash: string;          // MD5 of SQL query
  executionTimeMs: number;
  rowsReturned: number;
  timestamp: Date;
  tenantId: string;
  endpoint: string;           // GraphQL resolver or REST path
  userId?: string;
}

interface ApiPerformanceMetric {
  endpoint: string;
  method: string;
  statusCode: number;
  responseTimeMs: number;
  requestSizeBytes: number;
  responseSizeBytes: number;
  timestamp: Date;
  tenantId: string;
  userId?: string;
}

interface SystemPerformanceMetric {
  cpuUsagePercent: number;
  memoryUsedMB: number;
  memoryTotalMB: number;
  eventLoopLagMs: number;
  activeConnections: number;
  timestamp: Date;
}
```

**Implementation Strategy:**

1. **Database Query Instrumentation**
   - Wrap `pg.Pool.query()` with performance interceptor
   - Log queries exceeding configurable threshold (default: 500ms)
   - Store in `query_performance_log` table (time-series partitioned)

2. **GraphQL Resolver Instrumentation**
   - NestJS interceptor for all GraphQL resolvers
   - Track execution time per resolver
   - Aggregate to `api_endpoint_metrics` hourly

3. **System Metrics Collection**
   - Use Node.js `process.cpuUsage()` and `process.memoryUsage()`
   - Event loop monitoring via `perf_hooks`
   - Collect every 10 seconds, aggregate to 1-minute buckets

#### 2.2 Performance Dashboard Schema

**New GraphQL Schema:** `backend/src/graphql/schema/performance.graphql`

```graphql
# =====================================================
# PERFORMANCE ANALYTICS SCHEMA
# =====================================================

type Query {
  """
  Get system-wide performance overview
  """
  performanceOverview(
    facilityId: ID
    timeRange: TimeRange!
  ): PerformanceOverview!

  """
  Get slow queries in time range
  """
  slowQueries(
    facilityId: ID
    threshold: Int = 1000
    timeRange: TimeRange!
    limit: Int = 100
  ): [QueryPerformanceMetric!]!

  """
  Get API endpoint performance statistics
  """
  endpointMetrics(
    endpoint: String
    timeRange: TimeRange!
  ): [EndpointMetric!]!

  """
  Get resource utilization time series
  """
  resourceUtilization(
    facilityId: ID
    timeRange: TimeRange!
    interval: String = "5m"
  ): [ResourceMetric!]!

  """
  Get database connection pool health
  """
  databasePoolMetrics(
    timeRange: TimeRange!
  ): DatabasePoolMetrics!
}

type PerformanceOverview {
  timeRange: TimeRange!

  # Overall health
  healthScore: Float!           # 0-100
  status: HealthStatus!

  # API Performance
  avgResponseTimeMs: Float!
  p95ResponseTimeMs: Float!
  p99ResponseTimeMs: Float!
  requestsPerSecond: Float!
  errorRate: Float!

  # Database Performance
  avgQueryTimeMs: Float!
  slowQueryCount: Int!
  connectionPoolUtilization: Float!

  # Resource Utilization
  avgCpuUsagePercent: Float!
  avgMemoryUsageMB: Float!
  maxMemoryUsageMB: Float!

  # Trending
  performanceTrend: TrendDirection!
  topBottlenecks: [PerformanceBottleneck!]!
}

type QueryPerformanceMetric {
  id: ID!
  queryHash: String!
  queryPreview: String!         # First 200 chars
  executionTimeMs: Int!
  rowsReturned: Int!
  endpoint: String!
  timestamp: DateTime!
  occurrenceCount: Int!         # How many times this query ran
}

type EndpointMetric {
  endpoint: String!
  method: String!

  # Volume metrics
  totalRequests: Int!
  successfulRequests: Int!
  failedRequests: Int!

  # Performance metrics
  avgResponseTimeMs: Float!
  p50ResponseTimeMs: Float!
  p95ResponseTimeMs: Float!
  p99ResponseTimeMs: Float!
  maxResponseTimeMs: Float!

  # Data transfer
  avgRequestSizeBytes: Int!
  avgResponseSizeBytes: Int!

  # Trending
  trend: TrendDirection!
}

type ResourceMetric {
  timestamp: DateTime!
  cpuUsagePercent: Float!
  memoryUsedMB: Int!
  memoryTotalMB: Int!
  eventLoopLagMs: Float!
  activeConnections: Int!
  heapUsedMB: Int!
  heapTotalMB: Int!
}

type DatabasePoolMetrics {
  currentConnections: Int!
  idleConnections: Int!
  waitingRequests: Int!
  totalQueries: Int!
  avgQueryTimeMs: Float!
  utilizationPercent: Float!

  # Time series data
  utilizationHistory: [PoolUtilizationPoint!]!
}

type PoolUtilizationPoint {
  timestamp: DateTime!
  utilizationPercent: Float!
  activeConnections: Int!
  queuedRequests: Int!
}

type PerformanceBottleneck {
  type: BottleneckType!
  severity: Severity!
  description: String!
  impact: String!
  recommendation: String!
  affectedEndpoints: [String!]!
}

enum BottleneckType {
  SLOW_QUERY
  HIGH_CPU
  MEMORY_LEAK
  CONNECTION_POOL_EXHAUSTION
  N_PLUS_ONE_QUERY
  UNINDEXED_QUERY
  LARGE_PAYLOAD
}

enum TimeRange {
  LAST_HOUR
  LAST_6_HOURS
  LAST_24_HOURS
  LAST_7_DAYS
  LAST_30_DAYS
  CUSTOM
}

enum TrendDirection {
  IMPROVING
  STABLE
  DEGRADING
  CRITICAL
}

enum HealthStatus {
  HEALTHY
  DEGRADED
  UNHEALTHY
  CRITICAL
}

input CustomTimeRange {
  start: DateTime!
  end: DateTime!
}
```

#### 2.3 Database Schema (OLAP Tables)

**Migration:** `V0.0.40__add_performance_monitoring_olap.sql`

```sql
-- =====================================================
-- PERFORMANCE MONITORING OLAP TABLES
-- =====================================================

-- Query performance log (time-series partitioned)
CREATE TABLE query_performance_log (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v7(),
  tenant_id UUID NOT NULL,
  query_hash VARCHAR(32) NOT NULL,     -- MD5 hash
  query_preview TEXT,                  -- First 500 chars
  execution_time_ms INTEGER NOT NULL,
  rows_returned INTEGER,
  endpoint VARCHAR(255),
  user_id UUID,
  timestamp TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
  metadata JSONB
) PARTITION BY RANGE (timestamp);

-- Create monthly partitions (automated via pg_partman recommended)
CREATE TABLE query_performance_log_2025_12 PARTITION OF query_performance_log
  FOR VALUES FROM ('2025-12-01') TO ('2026-01-01');

CREATE TABLE query_performance_log_2026_01 PARTITION OF query_performance_log
  FOR VALUES FROM ('2026-01-01') TO ('2026-02-01');

-- Indexes
CREATE INDEX idx_query_perf_log_tenant_timestamp
  ON query_performance_log (tenant_id, timestamp DESC);

CREATE INDEX idx_query_perf_log_hash_timestamp
  ON query_performance_log (query_hash, timestamp DESC);

CREATE INDEX idx_query_perf_log_slow
  ON query_performance_log (execution_time_ms DESC)
  WHERE execution_time_ms > 1000;

-- API endpoint performance log (time-series partitioned)
CREATE TABLE api_performance_log (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v7(),
  tenant_id UUID NOT NULL,
  endpoint VARCHAR(255) NOT NULL,
  method VARCHAR(10) NOT NULL,
  status_code INTEGER NOT NULL,
  response_time_ms INTEGER NOT NULL,
  request_size_bytes INTEGER,
  response_size_bytes INTEGER,
  user_id UUID,
  timestamp TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
  metadata JSONB
) PARTITION BY RANGE (timestamp);

-- Create monthly partitions
CREATE TABLE api_performance_log_2025_12 PARTITION OF api_performance_log
  FOR VALUES FROM ('2025-12-01') TO ('2026-01-01');

CREATE TABLE api_performance_log_2026_01 PARTITION OF api_performance_log
  FOR VALUES FROM ('2026-01-01') TO ('2026-02-01');

-- Indexes
CREATE INDEX idx_api_perf_log_tenant_timestamp
  ON api_performance_log (tenant_id, timestamp DESC);

CREATE INDEX idx_api_perf_log_endpoint
  ON api_performance_log (endpoint, timestamp DESC);

CREATE INDEX idx_api_perf_log_slow
  ON api_performance_log (response_time_ms DESC)
  WHERE response_time_ms > 1000;

-- System resource metrics (1-minute aggregates)
CREATE TABLE system_resource_metrics (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v7(),
  tenant_id UUID NOT NULL,
  cpu_usage_percent NUMERIC(5,2),
  memory_used_mb INTEGER,
  memory_total_mb INTEGER,
  event_loop_lag_ms NUMERIC(10,2),
  active_connections INTEGER,
  heap_used_mb INTEGER,
  heap_total_mb INTEGER,
  timestamp TIMESTAMPTZ NOT NULL,
  UNIQUE(tenant_id, timestamp)
) PARTITION BY RANGE (timestamp);

-- Create monthly partitions
CREATE TABLE system_resource_metrics_2025_12 PARTITION OF system_resource_metrics
  FOR VALUES FROM ('2025-12-01') TO ('2026-01-01');

CREATE TABLE system_resource_metrics_2026_01 PARTITION OF system_resource_metrics
  FOR VALUES FROM ('2026-01-01') TO ('2026-02-01');

-- Index
CREATE INDEX idx_system_resource_tenant_timestamp
  ON system_resource_metrics (tenant_id, timestamp DESC);

-- =====================================================
-- OLAP CACHE: Hourly Performance Aggregates
-- =====================================================

CREATE TABLE performance_metrics_cache (
  tenant_id UUID NOT NULL,
  hour_bucket TIMESTAMPTZ NOT NULL,

  -- API metrics
  total_requests INTEGER NOT NULL DEFAULT 0,
  successful_requests INTEGER NOT NULL DEFAULT 0,
  failed_requests INTEGER NOT NULL DEFAULT 0,
  avg_response_time_ms NUMERIC(10,2),
  p95_response_time_ms INTEGER,
  p99_response_time_ms INTEGER,

  -- Database metrics
  total_queries INTEGER NOT NULL DEFAULT 0,
  slow_query_count INTEGER NOT NULL DEFAULT 0,
  avg_query_time_ms NUMERIC(10,2),

  -- Resource metrics
  avg_cpu_usage_percent NUMERIC(5,2),
  avg_memory_usage_mb INTEGER,
  max_memory_usage_mb INTEGER,
  avg_event_loop_lag_ms NUMERIC(10,2),

  -- Health score (0-100)
  health_score NUMERIC(5,2),

  last_updated TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
  PRIMARY KEY (tenant_id, hour_bucket)
);

-- Indexes
CREATE INDEX idx_perf_cache_hour ON performance_metrics_cache (hour_bucket DESC);
CREATE INDEX idx_perf_cache_health ON performance_metrics_cache (health_score ASC);

-- =====================================================
-- INCREMENTAL REFRESH FUNCTION (following V0.0.34 pattern)
-- =====================================================

CREATE OR REPLACE FUNCTION refresh_performance_metrics_incremental(
  p_tenant_id UUID DEFAULT NULL
)
RETURNS TABLE (
  hours_refreshed INTEGER,
  duration_ms INTEGER,
  status TEXT
) AS $$
DECLARE
  v_start_time TIMESTAMP;
  v_duration_ms INTEGER;
  v_hours_refreshed INTEGER := 0;
BEGIN
  v_start_time := CLOCK_TIMESTAMP();

  -- Aggregate last 24 hours of data into hourly buckets
  INSERT INTO performance_metrics_cache (
    tenant_id,
    hour_bucket,
    total_requests,
    successful_requests,
    failed_requests,
    avg_response_time_ms,
    p95_response_time_ms,
    p99_response_time_ms,
    total_queries,
    slow_query_count,
    avg_query_time_ms,
    avg_cpu_usage_percent,
    avg_memory_usage_mb,
    max_memory_usage_mb,
    avg_event_loop_lag_ms,
    health_score,
    last_updated
  )
  SELECT
    api.tenant_id,
    DATE_TRUNC('hour', api.timestamp) AS hour_bucket,

    -- API metrics
    COUNT(*) AS total_requests,
    COUNT(*) FILTER (WHERE status_code < 400) AS successful_requests,
    COUNT(*) FILTER (WHERE status_code >= 400) AS failed_requests,
    AVG(response_time_ms) AS avg_response_time_ms,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY response_time_ms) AS p95_response_time_ms,
    PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY response_time_ms) AS p99_response_time_ms,

    -- Database metrics
    COUNT(qpl.id) AS total_queries,
    COUNT(*) FILTER (WHERE qpl.execution_time_ms > 1000) AS slow_query_count,
    AVG(qpl.execution_time_ms) AS avg_query_time_ms,

    -- Resource metrics
    AVG(srm.cpu_usage_percent) AS avg_cpu_usage_percent,
    AVG(srm.memory_used_mb) AS avg_memory_usage_mb,
    MAX(srm.memory_used_mb) AS max_memory_usage_mb,
    AVG(srm.event_loop_lag_ms) AS avg_event_loop_lag_ms,

    -- Health score calculation (0-100)
    -- Lower is better for response times, higher for success rate
    GREATEST(0, LEAST(100,
      100 - (AVG(response_time_ms) / 10) - (COUNT(*) FILTER (WHERE status_code >= 500)::NUMERIC / COUNT(*) * 50)
    )) AS health_score,

    CURRENT_TIMESTAMP AS last_updated
  FROM api_performance_log api
  LEFT JOIN query_performance_log qpl
    ON api.tenant_id = qpl.tenant_id
    AND DATE_TRUNC('hour', api.timestamp) = DATE_TRUNC('hour', qpl.timestamp)
  LEFT JOIN system_resource_metrics srm
    ON api.tenant_id = srm.tenant_id
    AND DATE_TRUNC('hour', api.timestamp) = DATE_TRUNC('hour', srm.timestamp)
  WHERE api.timestamp >= NOW() - INTERVAL '24 hours'
    AND (p_tenant_id IS NULL OR api.tenant_id = p_tenant_id)
  GROUP BY api.tenant_id, DATE_TRUNC('hour', api.timestamp)
  ON CONFLICT (tenant_id, hour_bucket) DO UPDATE SET
    total_requests = EXCLUDED.total_requests,
    successful_requests = EXCLUDED.successful_requests,
    failed_requests = EXCLUDED.failed_requests,
    avg_response_time_ms = EXCLUDED.avg_response_time_ms,
    p95_response_time_ms = EXCLUDED.p95_response_time_ms,
    p99_response_time_ms = EXCLUDED.p99_response_time_ms,
    total_queries = EXCLUDED.total_queries,
    slow_query_count = EXCLUDED.slow_query_count,
    avg_query_time_ms = EXCLUDED.avg_query_time_ms,
    avg_cpu_usage_percent = EXCLUDED.avg_cpu_usage_percent,
    avg_memory_usage_mb = EXCLUDED.avg_memory_usage_mb,
    max_memory_usage_mb = EXCLUDED.max_memory_usage_mb,
    avg_event_loop_lag_ms = EXCLUDED.avg_event_loop_lag_ms,
    health_score = EXCLUDED.health_score,
    last_updated = CURRENT_TIMESTAMP;

  GET DIAGNOSTICS v_hours_refreshed = ROW_COUNT;
  v_duration_ms := EXTRACT(EPOCH FROM (CLOCK_TIMESTAMP() - v_start_time)) * 1000;

  RETURN QUERY SELECT v_hours_refreshed, v_duration_ms::INTEGER, 'SUCCESS'::TEXT;
END;
$$ LANGUAGE plpgsql;

COMMENT ON FUNCTION refresh_performance_metrics_incremental IS
  'Incrementally refresh performance metrics cache (last 24 hours). Expected: 50-100ms execution time.';

-- =====================================================
-- SCHEDULED REFRESH (every 5 minutes via pg_cron)
-- =====================================================

-- Requires pg_cron extension (install separately)
-- SELECT cron.schedule(
--   'refresh-performance-metrics',
--   '*/5 * * * *',  -- Every 5 minutes
--   $$SELECT refresh_performance_metrics_incremental()$$
-- );
```

#### 2.4 NestJS Service Implementation

**File:** `backend/src/modules/monitoring/services/performance-metrics.service.ts`

```typescript
import { Injectable, Inject, OnModuleInit } from '@nestjs/common';
import { Pool } from 'pg';
import * as crypto from 'crypto';

interface PerformanceOverview {
  timeRange: string;
  healthScore: number;
  status: 'HEALTHY' | 'DEGRADED' | 'UNHEALTHY' | 'CRITICAL';
  avgResponseTimeMs: number;
  p95ResponseTimeMs: number;
  p99ResponseTimeMs: number;
  requestsPerSecond: number;
  errorRate: number;
  avgQueryTimeMs: number;
  slowQueryCount: number;
  connectionPoolUtilization: number;
  avgCpuUsagePercent: number;
  avgMemoryUsageMB: number;
  maxMemoryUsageMB: number;
  performanceTrend: 'IMPROVING' | 'STABLE' | 'DEGRADING' | 'CRITICAL';
  topBottlenecks: any[];
}

@Injectable()
export class PerformanceMetricsService implements OnModuleInit {
  private metricsBuffer: any[] = [];
  private flushInterval: NodeJS.Timer;

  constructor(@Inject('DATABASE_POOL') private db: Pool) {}

  onModuleInit() {
    // Flush metrics buffer every 10 seconds
    this.flushInterval = setInterval(() => {
      this.flushMetrics();
    }, 10000);

    // Start system metrics collection
    this.startSystemMetricsCollection();
  }

  /**
   * Record query performance
   */
  async recordQueryPerformance(
    tenantId: string,
    query: string,
    executionTimeMs: number,
    rowsReturned: number,
    endpoint: string,
    userId?: string
  ) {
    const queryHash = crypto.createHash('md5').update(query).digest('hex');
    const queryPreview = query.substring(0, 500);

    this.metricsBuffer.push({
      type: 'query',
      tenantId,
      queryHash,
      queryPreview,
      executionTimeMs,
      rowsReturned,
      endpoint,
      userId,
      timestamp: new Date()
    });

    // Flush if buffer exceeds 100 items
    if (this.metricsBuffer.length >= 100) {
      await this.flushMetrics();
    }
  }

  /**
   * Record API performance
   */
  async recordApiPerformance(
    tenantId: string,
    endpoint: string,
    method: string,
    statusCode: number,
    responseTimeMs: number,
    requestSizeBytes: number,
    responseSizeBytes: number,
    userId?: string
  ) {
    this.metricsBuffer.push({
      type: 'api',
      tenantId,
      endpoint,
      method,
      statusCode,
      responseTimeMs,
      requestSizeBytes,
      responseSizeBytes,
      userId,
      timestamp: new Date()
    });

    if (this.metricsBuffer.length >= 100) {
      await this.flushMetrics();
    }
  }

  /**
   * Flush metrics buffer to database
   */
  private async flushMetrics() {
    if (this.metricsBuffer.length === 0) return;

    const metrics = [...this.metricsBuffer];
    this.metricsBuffer = [];

    const client = await this.db.connect();
    try {
      await client.query('BEGIN');

      // Insert query metrics
      const queryMetrics = metrics.filter(m => m.type === 'query');
      if (queryMetrics.length > 0) {
        const values = queryMetrics.map((m, idx) => {
          const base = idx * 8;
          return `($${base+1}, $${base+2}, $${base+3}, $${base+4}, $${base+5}, $${base+6}, $${base+7}, $${base+8})`;
        }).join(',');

        const params = queryMetrics.flatMap(m => [
          m.tenantId, m.queryHash, m.queryPreview, m.executionTimeMs,
          m.rowsReturned, m.endpoint, m.userId, m.timestamp
        ]);

        await client.query(`
          INSERT INTO query_performance_log (
            tenant_id, query_hash, query_preview, execution_time_ms,
            rows_returned, endpoint, user_id, timestamp
          ) VALUES ${values}
        `, params);
      }

      // Insert API metrics
      const apiMetrics = metrics.filter(m => m.type === 'api');
      if (apiMetrics.length > 0) {
        const values = apiMetrics.map((m, idx) => {
          const base = idx * 9;
          return `($${base+1}, $${base+2}, $${base+3}, $${base+4}, $${base+5}, $${base+6}, $${base+7}, $${base+8}, $${base+9})`;
        }).join(',');

        const params = apiMetrics.flatMap(m => [
          m.tenantId, m.endpoint, m.method, m.statusCode, m.responseTimeMs,
          m.requestSizeBytes, m.responseSizeBytes, m.userId, m.timestamp
        ]);

        await client.query(`
          INSERT INTO api_performance_log (
            tenant_id, endpoint, method, status_code, response_time_ms,
            request_size_bytes, response_size_bytes, user_id, timestamp
          ) VALUES ${values}
        `, params);
      }

      await client.query('COMMIT');
    } catch (error) {
      await client.query('ROLLBACK');
      console.error('[PerformanceMetrics] Failed to flush metrics:', error);
    } finally {
      client.release();
    }
  }

  /**
   * Start system metrics collection (every 10 seconds)
   */
  private startSystemMetricsCollection() {
    setInterval(async () => {
      const cpuUsage = process.cpuUsage();
      const memUsage = process.memoryUsage();

      const metric = {
        tenantId: 'system', // Or derive from context
        cpuUsagePercent: (cpuUsage.user + cpuUsage.system) / 1000000, // Convert to %
        memoryUsedMb: Math.round(memUsage.heapUsed / 1024 / 1024),
        memoryTotalMb: Math.round(memUsage.heapTotal / 1024 / 1024),
        eventLoopLagMs: 0, // Would use perf_hooks.monitorEventLoopDelay()
        activeConnections: this.db.totalCount - this.db.idleCount,
        heapUsedMb: Math.round(memUsage.heapUsed / 1024 / 1024),
        heapTotalMb: Math.round(memUsage.heapTotal / 1024 / 1024),
        timestamp: new Date()
      };

      try {
        await this.db.query(`
          INSERT INTO system_resource_metrics (
            tenant_id, cpu_usage_percent, memory_used_mb, memory_total_mb,
            event_loop_lag_ms, active_connections, heap_used_mb, heap_total_mb, timestamp
          ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
          ON CONFLICT (tenant_id, timestamp) DO NOTHING
        `, [
          metric.tenantId, metric.cpuUsagePercent, metric.memoryUsedMb,
          metric.memoryTotalMb, metric.eventLoopLagMs, metric.activeConnections,
          metric.heapUsedMb, metric.heapTotalMb, metric.timestamp
        ]);
      } catch (error) {
        console.error('[PerformanceMetrics] Failed to record system metrics:', error);
      }
    }, 10000);
  }

  /**
   * Get performance overview
   */
  async getPerformanceOverview(
    tenantId: string,
    timeRange: string = 'LAST_24_HOURS'
  ): Promise<PerformanceOverview> {
    const hoursBack = this.getHoursFromTimeRange(timeRange);

    const result = await this.db.query(`
      SELECT
        AVG(avg_response_time_ms) AS avg_response_time_ms,
        MAX(p95_response_time_ms) AS p95_response_time_ms,
        MAX(p99_response_time_ms) AS p99_response_time_ms,
        SUM(total_requests) / $2 AS requests_per_second,
        (SUM(failed_requests)::NUMERIC / NULLIF(SUM(total_requests), 0)) * 100 AS error_rate,
        AVG(avg_query_time_ms) AS avg_query_time_ms,
        SUM(slow_query_count) AS slow_query_count,
        AVG(avg_cpu_usage_percent) AS avg_cpu_usage_percent,
        AVG(avg_memory_usage_mb) AS avg_memory_usage_mb,
        MAX(max_memory_usage_mb) AS max_memory_usage_mb,
        AVG(health_score) AS health_score
      FROM performance_metrics_cache
      WHERE tenant_id = $1
        AND hour_bucket >= NOW() - INTERVAL '${hoursBack} hours'
    `, [tenantId, hoursBack * 3600]);

    const row = result.rows[0];
    const healthScore = parseFloat(row.health_score) || 0;

    return {
      timeRange,
      healthScore,
      status: this.getHealthStatus(healthScore),
      avgResponseTimeMs: parseFloat(row.avg_response_time_ms) || 0,
      p95ResponseTimeMs: parseInt(row.p95_response_time_ms) || 0,
      p99ResponseTimeMs: parseInt(row.p99_response_time_ms) || 0,
      requestsPerSecond: parseFloat(row.requests_per_second) || 0,
      errorRate: parseFloat(row.error_rate) || 0,
      avgQueryTimeMs: parseFloat(row.avg_query_time_ms) || 0,
      slowQueryCount: parseInt(row.slow_query_count) || 0,
      connectionPoolUtilization: ((this.db.totalCount - this.db.idleCount) / this.db.totalCount) * 100,
      avgCpuUsagePercent: parseFloat(row.avg_cpu_usage_percent) || 0,
      avgMemoryUsageMB: parseInt(row.avg_memory_usage_mb) || 0,
      maxMemoryUsageMB: parseInt(row.max_memory_usage_mb) || 0,
      performanceTrend: await this.calculateTrend(tenantId, hoursBack),
      topBottlenecks: await this.getTopBottlenecks(tenantId, hoursBack)
    };
  }

  private getHoursFromTimeRange(timeRange: string): number {
    const map: Record<string, number> = {
      'LAST_HOUR': 1,
      'LAST_6_HOURS': 6,
      'LAST_24_HOURS': 24,
      'LAST_7_DAYS': 168,
      'LAST_30_DAYS': 720
    };
    return map[timeRange] || 24;
  }

  private getHealthStatus(score: number): 'HEALTHY' | 'DEGRADED' | 'UNHEALTHY' | 'CRITICAL' {
    if (score >= 80) return 'HEALTHY';
    if (score >= 60) return 'DEGRADED';
    if (score >= 40) return 'UNHEALTHY';
    return 'CRITICAL';
  }

  private async calculateTrend(tenantId: string, hoursBack: number): Promise<any> {
    // Compare recent performance to previous period
    const result = await this.db.query(`
      SELECT
        AVG(health_score) FILTER (WHERE hour_bucket >= NOW() - INTERVAL '${hoursBack/2} hours') AS recent_score,
        AVG(health_score) FILTER (WHERE hour_bucket < NOW() - INTERVAL '${hoursBack/2} hours') AS previous_score
      FROM performance_metrics_cache
      WHERE tenant_id = $1
        AND hour_bucket >= NOW() - INTERVAL '${hoursBack} hours'
    `, [tenantId]);

    const recent = parseFloat(result.rows[0]?.recent_score) || 0;
    const previous = parseFloat(result.rows[0]?.previous_score) || 0;
    const delta = recent - previous;

    if (delta > 10) return 'IMPROVING';
    if (delta < -10) return 'DEGRADING';
    if (recent < 50) return 'CRITICAL';
    return 'STABLE';
  }

  private async getTopBottlenecks(tenantId: string, hoursBack: number): Promise<any[]> {
    // Get top slow queries
    const slowQueries = await this.db.query(`
      SELECT
        query_hash,
        query_preview,
        AVG(execution_time_ms) AS avg_time,
        COUNT(*) AS occurrence_count
      FROM query_performance_log
      WHERE tenant_id = $1
        AND timestamp >= NOW() - INTERVAL '${hoursBack} hours'
        AND execution_time_ms > 1000
      GROUP BY query_hash, query_preview
      ORDER BY avg_time DESC
      LIMIT 5
    `, [tenantId]);

    return slowQueries.rows.map(row => ({
      type: 'SLOW_QUERY',
      severity: row.avg_time > 5000 ? 'CRITICAL' : 'HIGH',
      description: `Slow query detected: ${row.query_preview.substring(0, 100)}...`,
      impact: `Average execution time: ${row.avg_time}ms (${row.occurrence_count} occurrences)`,
      recommendation: 'Add database index or optimize query structure',
      affectedEndpoints: []
    }));
  }
}
```

### 3. CACHING STRATEGY

#### Current State: ‚ùå NO DISTRIBUTED CACHING

**Problem:**
- No Redis integration
- No in-memory caching layer
- No GraphQL response caching
- Heavy database load for repeated queries

**Recommendation:**

1. **Add Redis Module**
   ```bash
   npm install @nestjs/cache-manager cache-manager cache-manager-redis-store redis
   ```

2. **Configure Caching in app.module.ts**
   ```typescript
   import { CacheModule } from '@nestjs/cache-manager';
   import * as redisStore from 'cache-manager-redis-store';

   @Module({
     imports: [
       CacheModule.register({
         isGlobal: true,
         store: redisStore,
         host: process.env.REDIS_HOST || 'redis',
         port: parseInt(process.env.REDIS_PORT || '6379'),
         ttl: 300, // 5 minutes default
       }),
       // ... other modules
     ]
   })
   ```

3. **Apply to Performance Queries**
   ```typescript
   @Query()
   @UseInterceptors(CacheInterceptor)
   @CacheTTL(60) // Cache for 60 seconds
   async performanceOverview(...) {
     // ...
   }
   ```

**Expected Impact:**
- 80-90% reduction in database load for dashboard queries
- Sub-100ms response time for cached queries
- Horizontal scalability (multiple backend instances)

### 4. FRONTEND DASHBOARD IMPLEMENTATION

#### Proposed Component Structure

```
frontend/src/pages/
‚îî‚îÄ‚îÄ PerformanceDashboard.tsx              # Main dashboard
    ‚îú‚îÄ‚îÄ components/
    ‚îÇ   ‚îú‚îÄ‚îÄ PerformanceOverviewCard.tsx   # Health score + KPIs
    ‚îÇ   ‚îú‚îÄ‚îÄ ResponseTimeChart.tsx         # Time-series line chart
    ‚îÇ   ‚îú‚îÄ‚îÄ SlowQueriesTable.tsx          # DataTable with slow queries
    ‚îÇ   ‚îú‚îÄ‚îÄ EndpointMetricsGrid.tsx       # API endpoint performance
    ‚îÇ   ‚îú‚îÄ‚îÄ ResourceUtilizationChart.tsx  # CPU/Memory/Connections
    ‚îÇ   ‚îî‚îÄ‚îÄ BottleneckAlerts.tsx          # Warning cards
```

**GraphQL Query:**
```typescript
// frontend/src/graphql/queries/performance.ts

import { gql } from '@apollo/client';

export const GET_PERFORMANCE_OVERVIEW = gql`
  query GetPerformanceOverview($facilityId: ID, $timeRange: TimeRange!) {
    performanceOverview(facilityId: $facilityId, timeRange: $timeRange) {
      healthScore
      status
      avgResponseTimeMs
      p95ResponseTimeMs
      p99ResponseTimeMs
      requestsPerSecond
      errorRate
      avgQueryTimeMs
      slowQueryCount
      connectionPoolUtilization
      avgCpuUsagePercent
      avgMemoryUsageMB
      performanceTrend
      topBottlenecks {
        type
        severity
        description
        impact
        recommendation
      }
    }
  }
`;

export const GET_SLOW_QUERIES = gql`
  query GetSlowQueries($timeRange: TimeRange!, $threshold: Int, $limit: Int) {
    slowQueries(timeRange: $timeRange, threshold: $threshold, limit: $limit) {
      id
      queryHash
      queryPreview
      executionTimeMs
      rowsReturned
      endpoint
      timestamp
      occurrenceCount
    }
  }
`;

export const GET_RESOURCE_UTILIZATION = gql`
  query GetResourceUtilization($timeRange: TimeRange!, $interval: String) {
    resourceUtilization(timeRange: $timeRange, interval: $interval) {
      timestamp
      cpuUsagePercent
      memoryUsedMB
      activeConnections
      eventLoopLagMs
    }
  }
`;
```

**Dashboard Component:**
```typescript
// frontend/src/pages/PerformanceDashboard.tsx

import React, { useState } from 'react';
import { useQuery } from '@apollo/client';
import { useTranslation } from 'react-i18next';
import { Activity, Database, Cpu, Zap } from 'lucide-react';
import { Chart } from '../components/common/Chart';
import { DataTable } from '../components/common/DataTable';
import { GET_PERFORMANCE_OVERVIEW, GET_SLOW_QUERIES, GET_RESOURCE_UTILIZATION } from '../graphql/queries/performance';

export const PerformanceDashboard: React.FC = () => {
  const { t } = useTranslation();
  const [timeRange, setTimeRange] = useState('LAST_24_HOURS');

  const { data: overview, loading: overviewLoading } = useQuery(GET_PERFORMANCE_OVERVIEW, {
    variables: { timeRange },
    pollInterval: 30000, // Refresh every 30 seconds
  });

  const { data: slowQueries } = useQuery(GET_SLOW_QUERIES, {
    variables: { timeRange, threshold: 1000, limit: 20 },
  });

  const { data: resourceData } = useQuery(GET_RESOURCE_UTILIZATION, {
    variables: { timeRange, interval: '5m' },
  });

  if (overviewLoading) return <div>Loading...</div>;

  const perf = overview?.performanceOverview;

  return (
    <div className="space-y-6">
      <h1 className="text-3xl font-bold">{t('performance.title')}</h1>

      {/* Health Score Card */}
      <div className="card bg-gradient-to-br from-primary-500 to-primary-600 text-white">
        <div className="flex items-center justify-between">
          <div>
            <p className="text-primary-100 text-sm font-medium">System Health Score</p>
            <p className="text-5xl font-bold mt-2">{perf?.healthScore.toFixed(1)}/100</p>
            <p className="text-primary-100 text-sm mt-1">
              Status: {perf?.status} | Trend: {perf?.performanceTrend}
            </p>
          </div>
          <Activity className="h-16 w-16 text-primary-200" />
        </div>
      </div>

      {/* KPI Grid */}
      <div className="grid grid-cols-1 md:grid-cols-4 gap-6">
        <div className="card">
          <div className="flex items-center justify-between">
            <div>
              <p className="text-gray-600 text-sm">Avg Response Time</p>
              <p className="text-2xl font-bold">{perf?.avgResponseTimeMs.toFixed(0)}ms</p>
              <p className="text-xs text-gray-500">P95: {perf?.p95ResponseTimeMs}ms</p>
            </div>
            <Zap className="h-10 w-10 text-primary-500" />
          </div>
        </div>

        <div className="card">
          <div className="flex items-center justify-between">
            <div>
              <p className="text-gray-600 text-sm">Requests/sec</p>
              <p className="text-2xl font-bold">{perf?.requestsPerSecond.toFixed(1)}</p>
              <p className="text-xs text-gray-500">Error Rate: {perf?.errorRate.toFixed(2)}%</p>
            </div>
            <Activity className="h-10 w-10 text-success-500" />
          </div>
        </div>

        <div className="card">
          <div className="flex items-center justify-between">
            <div>
              <p className="text-gray-600 text-sm">Avg Query Time</p>
              <p className="text-2xl font-bold">{perf?.avgQueryTimeMs.toFixed(0)}ms</p>
              <p className="text-xs text-gray-500">Slow Queries: {perf?.slowQueryCount}</p>
            </div>
            <Database className="h-10 w-10 text-warning-500" />
          </div>
        </div>

        <div className="card">
          <div className="flex items-center justify-between">
            <div>
              <p className="text-gray-600 text-sm">CPU Usage</p>
              <p className="text-2xl font-bold">{perf?.avgCpuUsagePercent.toFixed(1)}%</p>
              <p className="text-xs text-gray-500">Memory: {perf?.avgMemoryUsageMB}MB</p>
            </div>
            <Cpu className="h-10 w-10 text-danger-500" />
          </div>
        </div>
      </div>

      {/* Resource Utilization Chart */}
      <div className="card">
        <h2 className="text-xl font-bold mb-4">Resource Utilization (24h)</h2>
        <Chart
          data={resourceData?.resourceUtilization || []}
          lines={[
            { dataKey: 'cpuUsagePercent', name: 'CPU %', color: '#3b82f6' },
            { dataKey: 'memoryUsedMB', name: 'Memory (MB)', color: '#10b981' },
            { dataKey: 'activeConnections', name: 'DB Connections', color: '#f59e0b' },
          ]}
          xAxisKey="timestamp"
        />
      </div>

      {/* Slow Queries Table */}
      <div className="card">
        <h2 className="text-xl font-bold mb-4">Slow Queries (>1s)</h2>
        <DataTable
          data={slowQueries?.slowQueries || []}
          columns={[
            { accessorKey: 'queryPreview', header: 'Query' },
            { accessorKey: 'executionTimeMs', header: 'Time (ms)' },
            { accessorKey: 'occurrenceCount', header: 'Count' },
            { accessorKey: 'endpoint', header: 'Endpoint' },
          ]}
        />
      </div>

      {/* Bottleneck Alerts */}
      <div className="card">
        <h2 className="text-xl font-bold mb-4">Performance Bottlenecks</h2>
        <div className="space-y-3">
          {perf?.topBottlenecks.map((bottleneck: any, idx: number) => (
            <div key={idx} className="p-4 bg-warning-50 border-l-4 border-warning-500 rounded">
              <div className="flex items-start">
                <div className="flex-1">
                  <p className="font-medium text-warning-800">{bottleneck.description}</p>
                  <p className="text-sm text-warning-700 mt-1">{bottleneck.impact}</p>
                  <p className="text-sm text-warning-600 mt-2">
                    <strong>Fix:</strong> {bottleneck.recommendation}
                  </p>
                </div>
                <span className="px-2 py-1 text-xs font-semibold bg-warning-200 text-warning-800 rounded">
                  {bottleneck.severity}
                </span>
              </div>
            </div>
          ))}
        </div>
      </div>
    </div>
  );
};
```

---

## RISK ASSESSMENT

### High Risks (P1)

1. **Performance Overhead from Instrumentation** ‚ö†Ô∏è
   - **Risk:** Recording every query/API call adds latency
   - **Mitigation:**
     - Async buffered writes (10-second flush)
     - Sampling strategy (record 1 in 10 for fast queries <100ms)
     - Separate connection pool for metrics writes

2. **Database Growth (Time-Series Data)** ‚ö†Ô∏è
   - **Risk:** Metrics tables grow rapidly (10GB+/month)
   - **Mitigation:**
     - Partitioning by month (auto-drop old partitions)
     - Retention policy: 30 days raw data, 1 year aggregates
     - pg_partman for automated partition management

3. **No Alerting System** ‚ùå
   - **Risk:** Bottlenecks detected but no notifications
   - **Mitigation:**
     - Integrate with NATS alerts (publish to `agog.alerts.performance.>`)
     - Email/Slack notifications for CRITICAL health scores
     - Auto-escalation for repeated issues

### Medium Risks (P2)

1. **Cache Invalidation Complexity**
   - **Risk:** Stale cached data shown in dashboard
   - **Mitigation:** Conservative TTL (60 seconds), consider using `stale-while-revalidate`

2. **Multi-Tenant Data Isolation**
   - **Risk:** Tenant A sees Tenant B's performance data
   - **Mitigation:** Strict `tenant_id` filtering in all queries + RLS policies

### Low Risks (P3)

1. **Frontend Performance (Large Charts)**
   - **Risk:** Rendering 1000+ data points slows UI
   - **Mitigation:** Data aggregation + virtual scrolling

---

## IMPLEMENTATION ROADMAP

### Phase 1: Foundation (Week 1-2) - CRITICAL
- [ ] Database schema migration (V0.0.40)
- [ ] PerformanceMetricsService implementation
- [ ] Database query instrumentation (Pool wrapper)
- [ ] GraphQL schema definition
- [ ] Basic resolver implementation (no caching)

### Phase 2: Frontend Dashboard (Week 2-3)
- [ ] PerformanceDashboard component
- [ ] Chart integrations (response time, resources)
- [ ] Slow queries table
- [ ] Bottleneck alert cards

### Phase 3: Optimization (Week 3-4)
- [ ] Redis caching layer
- [ ] API interceptor for automatic metrics
- [ ] Sampling strategy for high-volume queries
- [ ] pg_cron scheduled refresh setup

### Phase 4: Production Hardening (Week 4-5)
- [ ] Performance testing (load test with 10k req/min)
- [ ] Partition management automation
- [ ] Alerting integration (NATS)
- [ ] Documentation + runbook

---

## DEPENDENCIES & PREREQUISITES

### Required Infrastructure
- ‚úÖ PostgreSQL 14+ with TimescaleDB recommended (for time-series optimization)
- ‚úÖ Redis 6+ for distributed caching
- ‚úÖ pg_cron extension for scheduled refreshes
- ‚ö†Ô∏è pg_partman extension for automated partition management

### Required NPM Packages (Backend)
```json
{
  "@nestjs/cache-manager": "^2.0.0",
  "cache-manager": "^5.2.0",
  "cache-manager-redis-store": "^3.0.0",
  "redis": "^4.6.0",
  "perf_hooks": "^0.0.1"  // Node.js built-in
}
```

### Environment Variables
```bash
# Performance Monitoring
PERFORMANCE_METRICS_ENABLED=true
PERFORMANCE_SAMPLING_RATE=0.1  # Record 10% of fast queries
SLOW_QUERY_THRESHOLD_MS=1000
METRICS_FLUSH_INTERVAL_MS=10000

# Redis Caching
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=
CACHE_TTL_SECONDS=60
```

---

## COMPARISON TO EXISTING SYSTEMS

### Vendor Performance Service (Reference Model) ‚úÖ

**File:** `backend/src/modules/procurement/services/vendor-performance.service.ts`

**What Works Well:**
- Comprehensive metrics interface (VendorPerformanceMetrics, VendorScorecard)
- Rolling averages and trend calculation
- UPSERT-based incremental updates
- Well-documented calculation formulas

**Pattern to Replicate:**
```typescript
// From vendor-performance.service.ts:206
async calculateVendorPerformance(
  tenantId: string,
  vendorId: string,
  year: number,
  month: number
): Promise<VendorPerformanceMetrics>
```

**Apply to Performance Dashboard:**
```typescript
async calculatePerformanceMetrics(
  tenantId: string,
  timeRange: TimeRange
): Promise<PerformanceMetrics>
```

**Lesson:** Use the same aggregation pattern for consistency.

### Health Controller (Good Foundation) ‚úÖ

**File:** `backend/src/health/health.controller.ts`

**What's Missing:**
- No historical tracking (only current state)
- No trend analysis
- No alerting thresholds

**Enhancement:** Integrate health checks into performance metrics:
```typescript
// Store health check results in performance_metrics_cache
INSERT INTO performance_metrics_cache (
  ...,
  database_health_status,
  connection_pool_health_status
) VALUES (...);
```

---

## RECOMMENDATIONS SUMMARY

### MUST IMPLEMENT (P1)

1. **Database Schema (V0.0.40)** - Foundation for all metrics
2. **Query Instrumentation** - Wrap `pg.Pool.query()` with timing
3. **PerformanceMetricsService** - Core metrics collection service
4. **GraphQL Schema** - Define `performance.graphql` schema
5. **Basic Dashboard** - Minimal viable UI showing health score + top metrics

### SHOULD IMPLEMENT (P2)

6. **Redis Caching** - Critical for dashboard performance
7. **API Interceptor** - Automatic API performance tracking
8. **Sampling Strategy** - Reduce overhead for high-volume queries
9. **Alerting Integration** - NATS alerts for critical issues
10. **Partition Management** - Automated cleanup of old data

### NICE TO HAVE (P3)

11. **Time-Series Database** - Consider TimescaleDB extension for PostgreSQL
12. **Real-Time Updates** - WebSocket subscriptions for live dashboard
13. **Query Plan Analysis** - Automatic EXPLAIN for slow queries
14. **Predictive Analytics** - ML-based bottleneck prediction

---

## ACCEPTANCE CRITERIA

### Functional Requirements
- [ ] Dashboard displays real-time health score (0-100)
- [ ] Shows P95/P99 response times for last 24 hours
- [ ] Lists slow queries (>1s) with occurrence counts
- [ ] Displays resource utilization charts (CPU, Memory, DB connections)
- [ ] Shows top 5 performance bottlenecks with recommendations
- [ ] Supports time range filtering (1h, 6h, 24h, 7d, 30d)
- [ ] Auto-refreshes every 30 seconds

### Performance Requirements
- [ ] Dashboard loads in <2 seconds (with caching)
- [ ] Metrics collection adds <10ms overhead per query
- [ ] OLAP refresh completes in <100ms (for 24h data)
- [ ] Handles 1000+ requests/minute without degradation

### Scalability Requirements
- [ ] Supports multi-tenant isolation (strict tenant_id filtering)
- [ ] Partitioned tables with automated cleanup (30-day retention)
- [ ] Horizontal scaling via Redis caching
- [ ] Database growth <1GB/month per tenant

---

## CONCLUSION

The Performance Analytics & Optimization Dashboard is **strategically critical** but requires **substantial architectural work** before implementation. The current monitoring infrastructure is minimal (stub data), and there is no query performance tracking or caching layer.

**My Recommendation:**
1. ‚úÖ **APPROVE** - But with **mandatory Phase 1 completion** before frontend work begins
2. ‚ö†Ô∏è **HIGH PRIORITY** - This is a foundational capability that will unblock future optimizations
3. üìã **FOLLOW THE OLAP PATTERN** - Reuse the proven incremental refresh architecture from bin utilization
4. üîß **IMPLEMENT INCREMENTALLY** - Start with basic metrics, add advanced features iteratively

**Estimated Effort:**
- Phase 1 (Foundation): **2-3 weeks** (Backend Dev + DBA)
- Phase 2 (Dashboard UI): **1-2 weeks** (Frontend Dev)
- Phase 3 (Optimization): **1-2 weeks** (DevOps + Backend)
- **Total: 4-7 weeks**

**Next Steps:**
1. Marcus (Implementation Lead) to review this critique
2. Roy (Backend) to implement Phase 1 (database schema + service)
3. Jen (Frontend) to design dashboard mockups
4. Berry (DevOps) to set up Redis and pg_cron infrastructure

---

**Prepared by:** Sylvia Chen
**Role:** Senior Software Architect
**Specialization:** System Architecture, Performance Optimization, Scalability
**Date:** 2025-12-29
**REQ:** REQ-STRATEGIC-AUTO-1767045901876

