# Promtail Configuration
# Purpose: Ship logs from Docker containers to Loki
# Collects logs from: backend, frontend, postgres, redis, nats, nginx

server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # ========================================================================
  # Docker Container Logs
  # ========================================================================
  - job_name: docker
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
        filters:
          - name: label
            values: ["agog.tier"]

    relabel_configs:
      # Add container name
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.*)'
        target_label: 'container'

      # Add container ID
      - source_labels: ['__meta_docker_container_id']
        target_label: 'container_id'

      # Add environment (blue/green)
      - source_labels: ['__meta_docker_container_label_agog_environment']
        target_label: 'environment'

      # Add tier (regional-cloud, edge, shared-infrastructure)
      - source_labels: ['__meta_docker_container_label_agog_tier']
        target_label: 'tier'

      # Add region
      - source_labels: ['__meta_docker_container_label_agog_region']
        target_label: 'region'

      # Add facility_id for edge containers
      - source_labels: ['__meta_docker_container_label_agog_facility_id']
        target_label: 'facility_id'

    pipeline_stages:
      # Parse JSON logs
      - json:
          expressions:
            level: level
            message: message
            timestamp: timestamp
            service: service
            trace_id: trace_id
            user_id: user_id
            tenant_id: tenant_id
            facility_id: facility_id

      # Extract log level
      - labels:
          level:
          service:
          tenant_id:
          facility_id:

      # Parse timestamp
      - timestamp:
          source: timestamp
          format: RFC3339

      # Drop health check logs (too noisy)
      - match:
          selector: '{container=~".*backend.*"} |= "GET /health"'
          action: drop

      # Drop metrics endpoint logs
      - match:
          selector: '{container=~".*backend.*"} |= "GET /metrics"'
          action: drop

  # ========================================================================
  # System Logs (journald)
  # ========================================================================
  - job_name: systemd
    journal:
      path: /var/log/journal
      max_age: 12h
      labels:
        job: systemd-journal

    relabel_configs:
      - source_labels: ['__journal__systemd_unit']
        target_label: 'unit'

      - source_labels: ['__journal__hostname']
        target_label: 'hostname'

      - source_labels: ['__journal_priority_keyword']
        target_label: 'level'

    pipeline_stages:
      # Map journal priority to log level
      - match:
          selector: '{level="emerg"}'
          stages:
            - static_labels:
                level: emergency

      - match:
          selector: '{level="alert"}'
          stages:
            - static_labels:
                level: alert

      - match:
          selector: '{level="crit"}'
          stages:
            - static_labels:
                level: critical

      - match:
          selector: '{level="err"}'
          stages:
            - static_labels:
                level: error

      - match:
          selector: '{level="warning"}'
          stages:
            - static_labels:
                level: warning

      - match:
          selector: '{level="notice"}'
          stages:
            - static_labels:
                level: notice

      - match:
          selector: '{level="info"}'
          stages:
            - static_labels:
                level: info

      - match:
          selector: '{level="debug"}'
          stages:
            - static_labels:
                level: debug

  # ========================================================================
  # NGINX Access Logs
  # ========================================================================
  - job_name: nginx
    static_configs:
      - targets:
          - localhost
        labels:
          job: nginx
          __path__: /var/log/nginx/*.log

    pipeline_stages:
      # Parse NGINX access log format
      - regex:
          expression: '^(?P<remote_addr>[\d\.]+) - (?P<remote_user>[^ ]*) \[(?P<time_local>[^\]]*)\] "(?P<method>\S+)(?: +(?P<path>[^\"]*?)(?: +\S*)?)?" (?P<status>\d+) (?P<body_bytes_sent>\d+) "(?P<http_referer>[^\"]*)" "(?P<http_user_agent>[^\"]*)"'

      - labels:
          method:
          status:

      - timestamp:
          source: time_local
          format: '02/Jan/2006:15:04:05 -0700'

      # Add log level based on status code
      - template:
          source: level
          template: '{{ if ge .status 500 }}error{{ else if ge .status 400 }}warning{{ else }}info{{ end }}'

      - labels:
          level:

  # ========================================================================
  # PostgreSQL Logs
  # ========================================================================
  - job_name: postgresql
    static_configs:
      - targets:
          - localhost
        labels:
          job: postgresql
          __path__: /var/log/postgresql/*.log

    pipeline_stages:
      # Parse PostgreSQL log format
      - regex:
          expression: '^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3} \w+) \[(?P<pid>\d+)\] (?P<level>\w+):  (?P<message>.*)'

      - labels:
          level:
          pid:

      - timestamp:
          source: timestamp
          format: '2006-01-02 15:04:05.000 MST'

      # Drop connection logs (too noisy)
      - match:
          selector: '{job="postgresql"} |= "connection authorized"'
          action: drop

      - match:
          selector: '{job="postgresql"} |= "connection received"'
          action: drop
